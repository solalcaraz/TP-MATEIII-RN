# -*- coding: utf-8 -*-
"""TP Mate RNN (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vMzDv1zzG88eieIGHa6X-wooONc-OsXr
"""



#import zipfile as zf
#files = zf.ZipFile("data/maestro-v3.0.0-midi.zip", 'r')
#files.extractall('data/')
#files.close()
!pip install pretty_midi
!pip install tensorflow

"""instalo todos los paquetes relevantes para procesar y escuchar archivos MIDI, glob para iterar sobre los archivos del dataset, collections para el diccionario con valor por defecto, y pathlib para abrir el archivo."""

import collections
import glob
import numpy as np
import pathlib
import pandas as pd
import pretty_midi
import tensorflow as tf

"""utilizamos tres variables para definir una "nota", tono (pitch), step, y duración.
tono es la calidad sonora de la nota, lo que la distingue de otras.
step es el tiempo entre el inicio de una nota y el inicio de la previa
duración lo que dura en milisegundos cada nota.
"""

#directorio = pathlib.Path('data/maestro-v3.0.0')
#filenames = glob.glob(str(data_dir/'**/*.mid*'))

sample_file = "/content/MIDI-Unprocessed_01_R1_2008_01-04_ORIG_MID--AUDIO_01_R1_2008_wav--3.midi"
print(sample_file)

def midi_a_notas(midifile: str) -> pd.DataFrame:
    pm = pretty_midi.PrettyMIDI(midifile)
    instrumento = pm.instruments[0]
    notas = collections.defaultdict(list)

    notas_orden = sorted(instrumento.notes, key=lambda nota: nota.start)
    previa_inicio = notas_orden[0].start

    for nota in notas_orden:
        inicio = nota.start
        fin = nota.end
        notas['pitch'].append(nota.pitch)

    return pd.DataFrame({nombre: np.array(valor) for nombre, valor in notas.items()})

"""Codigo robado: escribe un dataframe con notas en un archivo midi y lo devuelve como prettyMIDI para poder escucharlo:"""

def notes_to_midi(
  notes: pd.DataFrame,
  out_file: str,
  instrument_name: str,
  velocity: int = 100,  # note loudness
) -> pretty_midi.PrettyMIDI:

  pm = pretty_midi.PrettyMIDI()
  instrument = pretty_midi.Instrument(
      program=pretty_midi.instrument_name_to_program(
          instrument_name))

  prev_start = 0
  for i, note in notes.iterrows():
    start = float(prev_start + note['step'])
    end = float(start + note['duration'])
    note = pretty_midi.Note(
        velocity=velocity,
        pitch=int(note['pitch']),
        start=start,
        end=end,
    )
    instrument.notes.append(note)
    prev_start = start

  pm.instruments.append(instrument)
  pm.write(out_file)
  return pm

notasGlobal = []
tam_muestra = 10
#for f in filenames[:tam_muestra]:
notas = midi_a_notas(sample_file)
    #notasGlobal.append(notas)
#notasGlobal = pd.concat(notasGlobal)

indice_notas = ['pitch']
notas_entrenamiento = np.stack([notas[key] for key in indice_notas], axis=1)
np.set_printoptions(precision=3)
dataset_nota = tf.data.Dataset.from_tensor_slices(notas_entrenamiento)
print(notas_entrenamiento)
print(list(dataset_nota.as_numpy_iterator()))

def ventanizar(dataset, tam_ventana, alfabeto_notas = 128,) -> tf.data.Dataset:
  tam_ventana = tam_ventana+1

  windows = dataset.window(tam_ventana, shift=1, stride=1, drop_remainder=True)
    
  flatten = lambda x: x.batch(tam_ventana, drop_remainder=True)
  sequences = windows.flat_map(flatten)
  # Normalize tono de las notas
  def normalizar_tono(x):
    x = x/tam_ventana
    return x
  # Partimos los indices
  def partir_indices(sequences):
    inputs = sequences[:-1]
    outputs_dense = sequences[-1]

    return normalizar_tono(inputs), outputs_dense

  return sequences.map(partir_indices)

ventanitas = ventanizar(dataset_nota, 100)
